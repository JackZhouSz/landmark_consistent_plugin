reduction: sum

weight_dad3d: 1.0

weight_proj:  1.0
weight_proj_ref_gt: 1.0
weight_proj_srt_gt: 1.0
weight_lm2d:  1.0
weight_mesh:  1.0
our_weight: 0.1 # dad3d*weight_dad3d + our_loss * our_weight
our_proj: 1.0 # our_loss = (proj + proj_ref_gt + proj_srt_gt) * our_proj + lm2d + mesh*our_mesh
our_mesh: 1.0 # our_loss = (proj + proj_ref_gt + proj_srt_gt) * our_proj + lm2d + mesh*our_mesh
weight_jaw_pseudo: 1.0 # for pseudo ground truth landmarks of sampled views, jaw points, 0-16, may not be accurate, so set a low weight instead of 1.0 as other points

num_views_srt: 4 # we use 4 views to calculate srt 3d facial landmark

criterions:
  -
    name: heatmap_loss
    target_key: TARGET_LANDMARKS_HEATMAP
    output_key: OUTPUT_LANDMARKS_HEATMAP
    weight: 1.
    loss:
      _target_: model_training.losses.IoULoss

  -
    name: vertices3d_loss
    target_key: TARGET_3D_MODEL_VERTICES
    output_key: OUTPUT_3DMM_PARAMS
    weight: 50.
    loss:
      _target_: model_training.losses.Vertices3DLoss
      criterion: l2 # choose from {l1, l2, smooth_l1}
      batch_size: ${batch_size}
      consts: ${constants}
      weights_and_indices:
        flame_indices: ${train.flame_indices}
        weights: {'head': .5, 'face_w_ears': .75, 'face': 1.}


  - name: reprojection_loss
    target_key: TARGET_2D_FULL_LANDMARKS
    output_key: OUTPUT_3DMM_PARAMS
    weight: 0.05
    loss:
      _target_: model_training.losses.ReprojectionLoss
      criterion: smooth_l1
      batch_size: ${batch_size}
      consts: ${constants}
      img_size: ${train.img_size}
      weights_and_indices:
        flame_indices: ${train.flame_indices}
        weights: {'face': .5, 'face_w_ears': .5}

  - name: landmarks_loss
    target_key:
      - TARGET_2D_LANDMARKS
      - TARGET_2D_LANDMARKS_PRESENCE
    output_key:
      - OUTPUT_2D_LANDMARKS
      - TARGET_2D_LANDMARKS_PRESENCE
    weight: 100.
    loss:
      _target_: model_training.losses.LandmarksLossWVisibility
      criterion: smooth_l1
